{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load strain design data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from src.dataloader import DataLoader\n",
    "from src.machinelearning import MachineLearning\n",
    "from src.optimization import Optimization\n",
    "\n",
    "# Load the data\n",
    "DBTL_A = [\n",
    "    \"2X.Mh\",\n",
    "    \"B.Lm\",\n",
    "    \"2X.Ll\",\n",
    "    \"A.Mm\",\n",
    "    \"B.Ll\",\n",
    "    \"A.Mh\",\n",
    "    \"2X.Lm\",\n",
    "    \"A.Hl\",\n",
    "    \"2X.Hh\",\n",
    "    \"B.Ml\",\n",
    "    \"B.Mm\",\n",
    "    \"2X.Lh\",\n",
    "    \"B.Mh\",\n",
    "    \"2X.Hl\",\n",
    "    \"B.Hl\",\n",
    "    \"2X.Ml\",\n",
    "    \"B.Hm\",\n",
    "    \"B.Lh\",\n",
    "    \"B.Hh\",\n",
    "    \"A.Ll\",\n",
    "    \"A.Hm\",\n",
    "    \"2X.Mm\",\n",
    "    \"A.Hh\",\n",
    "    \"A.Ml\",\n",
    "    \"A.Lm\",\n",
    "    \"A.Lh\",\n",
    "    \"2X.Hm\",\n",
    "]\n",
    "DBTL_B = [\"BL.Mm\", \"BL.Mh\", \"BL.Ml\"]\n",
    "FILENAME = \"preprocessed_Limonene_data.csv\"\n",
    "\n",
    "data = DataLoader(FILENAME, target=\"Limonene\")\n",
    "df = data.df.copy()\n",
    "df_A = df.loc[DBTL_A]\n",
    "df_B = df.loc[DBTL_B]\n",
    "\n",
    "print(f\"DBTL_A shape: {df_A.shape}\")\n",
    "print(f\"DBTL_B shape: {df_B.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML-based optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, x_offset, x_factor, y_offset, y_factor, scaled_lb, scaled_ub = data.normalization(\n",
    "    df=df_A\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "VALIDATION_SPLIT = 0.33\n",
    "\n",
    "net = MachineLearning(\n",
    "    input_dim=x.shape[1],\n",
    "    output_dim=y.shape[1],\n",
    "    num_hidden=3,\n",
    "    hidden_dim=3,\n",
    "    activation=\"sigmoid\",\n",
    "    lr=0.01,\n",
    ")\n",
    "\n",
    "net.create_model()\n",
    "net.train(x, y, EPOCHS, BATCH_SIZE, VALIDATION_SPLIT)\n",
    "net.loss_curve()\n",
    "net.save_model(\"reformer_nn.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add 2 to all x_offset keys values\n",
    "# x_offset = {key: value + 2 for key, value in x_offset.items()}\n",
    "# y_offset = {key: value + 10 for key, value in y_offset.items()}\n",
    "\n",
    "# x_factor = {key: value * 2 for key, value in x_factor.items()}\n",
    "# y_factor = {key: value * 2 for key, value in y_factor.items()}\n",
    "\n",
    "# scaled_lb = scaled_lb * .005\n",
    "# scaled_ub = scaled_ub * 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omlt = Optimization(\n",
    "    model_file=\"reformer_nn.keras\", inputs=data.inputs, outputs=data.outputs\n",
    ")\n",
    "omlt.set_scaler(x_offset, x_factor, y_offset, y_factor, scaled_lb, scaled_ub)\n",
    "omlt.load_net()\n",
    "omlt.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gradient Boosting Trees__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: DEPRECATED: Declaring class 'OmltBlockData' derived from\n",
      "'_BlockData'. The class '_BlockData' has been renamed to 'BlockData'.\n",
      "(deprecated in 6.7.2) (called from\n",
      "c:\\Users\\mexis\\anaconda3\\envs\\main\\lib\\site-packages\\omlt\\block.py:33)\n",
      "WARNING:tensorflow:From c:\\Users\\mexis\\anaconda3\\envs\\main\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyomo.environ as pe\n",
    "from omlt import OffsetScaling, OmltBlock\n",
    "from omlt.gbt import GBTBigMFormulation, GradientBoostedTreeModel\n",
    "from omlt.gbt.model import GradientBoostedTreeModel\n",
    "from omlt.io.keras import load_keras_sequential\n",
    "from omlt.neuralnet import FullSpaceSmoothNNFormulation\n",
    "from onnxmltools.convert import convert_sklearn, convert_xgboost\n",
    "from skl2onnx import to_onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBTL_A shape: (27, 10)\n",
      "DBTL_B shape: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "DBTL_A = [\"2X.Mh\", \"B.Lm\", \"2X.Ll\", \"A.Mm\", \"B.Ll\", \"A.Mh\", \"2X.Lm\", \"A.Hl\", \"2X.Hh\", \"B.Ml\", \"B.Mm\", \"2X.Lh\", \"B.Mh\", \"2X.Hl\", \"B.Hl\", \"2X.Ml\", \"B.Hm\", \"B.Lh\", \"B.Hh\", \"A.Ll\", \"A.Hm\", \"2X.Mm\", \"A.Hh\", \"A.Ml\", \"A.Lm\", \"A.Lh\", \"2X.Hm\"]\n",
    "DBTL_B = [\"BL.Mm\", \"BL.Mh\", \"BL.Ml\"]\n",
    "FILENAME = \"preprocessed_Limonene_data.csv\"\n",
    "\n",
    "df = pd.read_csv(FILENAME, index_col=0)\n",
    "\n",
    "inputs = df.drop(columns=[\"Limonene\"]).columns.values.tolist()\n",
    "outputs = [\"Limonene\"]\n",
    "\n",
    "df_A = df.loc[DBTL_A]\n",
    "df_B = df.loc[DBTL_B]\n",
    "\n",
    "print(f\"DBTL_A shape: {df_A.shape}\")\n",
    "print(f\"DBTL_B shape: {df_B.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data scaling and scaler creation\n",
    "dfin = df_A[inputs]\n",
    "dfout = df_A[outputs]\n",
    "\n",
    "x_offset, x_factor = dfin.mean().to_dict(), dfin.std().to_dict()\n",
    "y_offset, y_factor = dfout.mean().to_dict(), dfout.std().to_dict()\n",
    "\n",
    "dfin = (dfin - dfin.mean()).divide(dfin.std())\n",
    "dfout = (dfout - dfout.mean()).divide(dfout.std())\n",
    "\n",
    "scaled_lb = dfin.min()[inputs].values\n",
    "scaled_ub = dfin.max()[inputs].values\n",
    "\n",
    "scaler = OffsetScaling(\n",
    "        offset_inputs={i: x_offset[inputs[i]] for i in range(len(inputs))},\n",
    "        factor_inputs={i: x_factor[inputs[i]] for i in range(len(inputs))},\n",
    "        offset_outputs={i: y_offset[outputs[i]] for i in range(len(outputs))},\n",
    "        factor_outputs={i: y_factor[outputs[i]] for i in range(len(outputs))}\n",
    "    )\n",
    "\n",
    "scaled_input_bounds = {i: (scaled_lb[i], scaled_ub[i]) for i in range(len(inputs))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_train_rf(X_train, y_train):\n",
    "    param_grid = {\n",
    "        \"n_estimators\": np.linspace(3, 100, 100, dtype=int),\n",
    "        \"max_depth\": np.linspace(2, 25, 100, dtype=int),\n",
    "        \"min_samples_split\": np.linspace(0.1, 1.0, 100),\n",
    "        \"min_samples_leaf\": np.linspace(0.1, 0.5, 100)\n",
    "    }\n",
    "    \n",
    "    grid = RandomizedSearchCV(RandomForestRegressor(), param_distributions=param_grid,\n",
    "                                n_iter=500, cv=3, verbose=3, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_estimator_\n",
    "\n",
    "def tune_and_train_gbt(X_train, y_train):\n",
    "    param_grid = {\n",
    "        \"n_estimators\": np.linspace(3, 100, 100, dtype=int),\n",
    "        \"max_depth\": np.linspace(2, 25, 100, dtype=int),\n",
    "        \"min_samples_split\": np.linspace(0.1, 1.0, 100),\n",
    "        \"min_samples_leaf\": np.linspace(0.1, 0.5, 100)\n",
    "    }\n",
    "    \n",
    "    grid = RandomizedSearchCV(GradientBoostingRegressor(), param_distributions=param_grid,\n",
    "                                n_iter=500, cv=3, verbose=3, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df_A.drop(columns=[\"Limonene\"]).values\n",
    "# y_train = df_A[\"Limonene\"].values\n",
    "\n",
    "X_train = dfin.values\n",
    "y_train = dfout.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n",
      "CV Score: 0.8072867370691753\n"
     ]
    }
   ],
   "source": [
    "# dtr = RandomForestRegressor()\n",
    "# dtr.fit(X_train, y_train)\n",
    "\n",
    "dtr = tune_and_train_rf(X_train, y_train)\n",
    "# dtr = tune_and_train_gbt(X_train, y_train)\n",
    "\n",
    "cv_score = cross_val_score(dtr, X_train, y_train, scoring='neg_mean_absolute_error', cv=5)\n",
    "print(f\"CV Score: {-cv_score.mean()}\")\n",
    "\n",
    "float_tensor_type = FloatTensorType([None, X_train.shape[1]])\n",
    "initial_types = [(\"float_input\", float_tensor_type)]\n",
    "try:\n",
    "    onnx_model = convert_sklearn(dtr, initial_types=initial_types)\n",
    "except Exception:\n",
    "    onnx_model = convert_xgboost(dtr, initial_types=initial_types)\n",
    "\n",
    "results = pd.DataFrame({\"pred\": dtr.predict(X_train), \"true\": y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipopt 3.11.1: \n",
      "==> Warning: Treating 158 binary and 0 integer variables as continous.\n",
      "\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "NOTE: You are using Ipopt by default with the MUMPS linear solver.\n",
      "      Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "\n",
      "This is Ipopt version 3.11.1, running with linear solver mumps.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:      787\n",
      "Number of nonzeros in inequality constraint Jacobian.:     2506\n",
      "Number of nonzeros in Lagrangian Hessian.............:        0\n",
      "\n",
      "Total number of variables............................:      561\n",
      "                     variables with only lower bounds:      383\n",
      "                variables with lower and upper bounds:      176\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:       91\n",
      "Total number of inequality constraints...............:     1072\n",
      "        inequality constraints with only lower bounds:        1\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:     1071\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 -0.0000000e+000 3.11e+001 1.74e+000  -1.0 0.00e+000    -  0.00e+000 0.00e+000   0\n",
      "   1 -4.9001072e-001 3.07e+001 1.74e+000  -1.0 3.32e+001    -  8.86e-003 1.48e-002f  1\n",
      "   2 -1.4031422e+000 2.99e+001 1.69e+000  -1.0 3.48e+001    -  1.61e-002 2.63e-002f  1\n",
      "   3 -3.4650931e+000 2.81e+001 1.59e+000  -1.0 3.56e+001    -  4.22e-002 5.79e-002f  1\n",
      "   4 -9.2087075e+000 2.35e+001 3.19e+000  -1.0 3.49e+001    -  9.31e-002 1.64e-001f  1\n",
      "   5 -3.5657604e+001 3.65e+000 8.95e+000  -1.0 3.13e+001    -  3.00e-001 8.45e-001f  1\n",
      "   6 -4.0226977e+001 1.49e+000 3.90e+000  -1.0 7.70e+000    -  4.94e-001 5.93e-001f  1\n",
      "   7 -4.2279367e+001 8.70e-001 2.36e+000  -1.0 4.95e+000    -  7.52e-001 4.14e-001f  1\n",
      "   8 -4.4557141e+001 3.17e-001 2.81e+000  -1.0 3.58e+000    -  9.33e-001 6.36e-001h  1\n",
      "   9 -4.5122617e+001 1.41e-001 4.27e+000  -1.0 1.02e+000    -  7.02e-001 5.54e-001h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10 -4.5368131e+001 6.35e-002 2.25e+001  -1.0 4.46e-001    -  1.00e+000 5.51e-001h  1\n",
      "  11 -4.5478767e+001 2.62e-002 5.15e+001  -1.0 1.89e-001    -  1.00e+000 5.87e-001h  1\n",
      "  12 -4.5523756e+001 1.08e-002 1.23e+002  -1.0 7.66e-002    -  1.00e+000 5.88e-001h  1\n",
      "  13 -4.5542616e+001 4.49e-003 3.00e+002  -1.0 3.22e-002    -  1.00e+000 5.85e-001h  1\n",
      "  14 -4.5550295e+001 1.86e-003 7.22e+002  -1.0 1.31e-002    -  1.00e+000 5.86e-001h  1\n",
      "  15 -4.5553539e+001 7.70e-004 1.74e+003  -1.0 5.54e-003    -  1.00e+000 5.86e-001h  1\n",
      "  16 -4.5554855e+001 3.18e-004 4.21e+003  -1.0 2.25e-003    -  1.00e+000 5.86e-001h  1\n",
      "  17 -4.5555412e+001 1.32e-004 1.01e+004  -1.0 9.49e-004    -  1.00e+000 5.86e-001h  1\n",
      "  18 -4.5555637e+001 5.43e-005 2.43e+004  -1.0 3.84e-004    -  1.00e+000 5.88e-001h  1\n",
      "  19 -4.5555733e+001 2.23e-005 5.80e+004  -1.0 1.62e-004    -  1.00e+000 5.90e-001h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20 -4.5555772e+001 9.00e-006 1.35e+005  -1.0 6.50e-005    -  1.00e+000 5.96e-001h  1\n",
      "  21 -4.5555788e+001 3.51e-006 3.02e+005  -1.0 2.68e-005    -  1.00e+000 6.10e-001h  1\n",
      "  22 -4.5555795e+001 1.24e-006 5.97e+005  -1.0 1.02e-005    -  1.00e+000 6.46e-001h  1\n",
      "  23 -4.5555797e+001 3.22e-007 8.23e+005  -1.0 3.71e-006    -  1.00e+000 7.40e-001h  1\n",
      "  24 -4.5555797e+001 3.19e-007 4.10e+006  -1.0 9.26e-007    -  1.00e+000 7.81e-003h  8\n",
      "  25 -4.5555798e+001 4.25e-010 1.00e-006  -1.0 9.27e-007    -  1.00e+000 1.00e+000h  1\n",
      "  26 -5.1817075e+001 2.03e-009 4.13e+006  -8.6 6.26e+000    -  5.63e-001 1.00e+000f  1\n",
      "  27 -6.0124310e+001 1.37e-009 2.77e+006  -8.6 9.79e+000    -  4.41e-001 8.48e-001f  1\n",
      "  28 -6.5085881e+001 9.69e-010 1.45e+006  -8.6 7.88e+000    -  4.58e-001 6.29e-001f  1\n",
      "  29 -6.9143461e+001 2.37e-009 8.02e+005  -8.6 5.27e+000    -  4.10e-001 7.70e-001f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  30 -7.0350509e+001 1.23e-008 4.03e+005  -8.6 1.86e+000    -  4.90e-001 6.50e-001f  1\n",
      "  31 -7.0736796e+001 1.40e-008 1.85e+005  -8.6 7.81e-001    -  5.49e-001 4.95e-001f  1\n",
      "In iteration 31, 1 Slack too small, adjusting variable bound\n",
      "  32 -7.1032222e+001 4.98e-007 8.22e+004  -8.6 4.69e-001    -  7.10e-001 6.47e-001f  1\n",
      "  33 -7.1148009e+001 1.62e-007 5.75e+004  -8.6 2.70e-001    -  3.01e-001 6.65e-001f  1\n",
      "  34 -7.1191948e+001 3.96e-008 2.50e+004  -8.6 1.80e-001    -  5.66e-001 7.26e-001f  1\n",
      "  35 -7.1200533e+001 1.18e-008 1.36e+004  -8.6 1.83e-002    -  4.58e-001 6.01e-001f  1\n",
      "  36 -7.1202925e+001 2.79e-007 6.96e+003  -8.6 6.83e-003    -  4.86e-001 4.33e-001f  1\n",
      "  37 -7.1205895e+001 3.54e-007 5.70e+003  -8.6 3.78e-003    -  1.91e-001 9.55e-001f  1\n",
      "  38 -7.1206004e+001 1.84e-007 3.58e+003  -8.6 1.34e-004    -  3.79e-001 8.16e-001f  1\n",
      "  39 -7.1206019e+001 9.38e-008 2.20e+003  -8.6 5.95e-005    -  3.90e-001 6.30e-001f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  40 -7.1206024e+001 6.69e-008 1.18e+003  -8.6 1.01e-004    -  4.70e-001 5.53e-001f  1\n",
      "  41 -7.1206025e+001 4.72e-008 5.19e+002  -8.6 1.92e-004    -  5.51e-001 4.46e-001f  1\n",
      "  42 -7.1206026e+001 2.82e-008 1.97e+002  -8.6 4.28e-004    -  6.24e-001 6.42e-001f  1\n",
      "  43 -7.1206027e+001 1.04e-008 2.18e+001  -8.6 1.13e-003    -  8.88e-001 8.86e-001f  1\n",
      "In iteration 43, 1 Slack too small, adjusting variable bound\n",
      "  44 -7.1206027e+001 6.95e-009 1.26e+001  -8.6 9.84e-003    -  9.92e-001 8.57e-001f  1\n",
      "  45 -7.1206027e+001 6.67e-009 8.47e+000  -8.6 2.44e-001    -  8.96e-001 1.00e+000h  1\n",
      "  46 -7.1206027e+001 6.67e-009 7.27e+001  -8.6 4.08e-002    -  2.92e-001 1.00e+000h  1\n",
      "  47 -7.1206027e+001 6.67e-009 1.06e-010  -8.6 9.02e-004    -  1.00e+000 1.00e+000h  1\n",
      "\n",
      "Number of Iterations....: 47\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............: -7.1206026837272574e+001  -7.1206026837272574e+001\n",
      "Dual infeasibility......:  1.0555572326365616e-010   1.0555572326365616e-010\n",
      "Constraint violation....:  6.6666836495699044e-009   6.6666836495699044e-009\n",
      "Complementarity.........:  9.0118272800966542e-009   9.0118272800966542e-009\n",
      "Overall NLP error.......:  6.6666836495699044e-009   9.0118272800966542e-009\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 55\n",
      "Number of objective gradient evaluations             = 48\n",
      "Number of equality constraint evaluations            = 55\n",
      "Number of inequality constraint evaluations          = 55\n",
      "Number of equality constraint Jacobian evaluations   = 48\n",
      "Number of inequality constraint Jacobian evaluations = 48\n",
      "Number of Lagrangian Hessian evaluations             = 47\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.502\n",
      "Total CPU secs in NLP function evaluations           =      0.001\n",
      "\n",
      "EXIT: Optimal Solution Found.\n"
     ]
    }
   ],
   "source": [
    "def add_tree_model(opt_model, onnx_model, scaler, scaled_input_bounds):\n",
    "    # init omlt block and gbt model based on the onnx format\n",
    "    opt_model.gbt = OmltBlock()\n",
    "    gbt_model = GradientBoostedTreeModel(onnx_model, scaling_object=scaler, scaled_input_bounds=scaled_input_bounds)\n",
    "\n",
    "    # omlt uses a big-m formulation to encode the tree models\n",
    "    formulation = GBTBigMFormulation(gbt_model)\n",
    "    opt_model.gbt.build_formulation(formulation)\n",
    "\n",
    "\n",
    "opt_model = pe.ConcreteModel()\n",
    "add_tree_model(opt_model, onnx_model, scaler, scaled_input_bounds)\n",
    "\n",
    "# Add objective and constraints\n",
    "opt_model.obj = pe.Objective(expr=opt_model.gbt.outputs[0], sense=pe.maximize)\n",
    "\n",
    "Q40322_MENSP_idx = inputs.index('Q40322_MENSP')\n",
    "opt_model.cons = pe.Constraint(expr=opt_model.gbt.inputs[Q40322_MENSP_idx] >= 8)\n",
    "\n",
    "solver = pe.SolverFactory(\"ipopt\")\n",
    "status = solver.solve(opt_model, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value 71.2060266994846\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MVD1_YEAST</th>\n",
       "      <td>1.50620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q40322_MENSP</th>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDI_ECOLI</th>\n",
       "      <td>2.42820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATOB_ECOLI</th>\n",
       "      <td>0.25095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q8LKJ3_ABIGR</th>\n",
       "      <td>1.59150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9FD87_STAAU</th>\n",
       "      <td>0.27925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9FD86_STAAU</th>\n",
       "      <td>0.08545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIME_YEAST</th>\n",
       "      <td>0.35120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERG8_YEAST</th>\n",
       "      <td>0.48190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Value\n",
       "MVD1_YEAST    1.50620\n",
       "Q40322_MENSP  9.00000\n",
       "IDI_ECOLI     2.42820\n",
       "ATOB_ECOLI    0.25095\n",
       "Q8LKJ3_ABIGR  1.59150\n",
       "Q9FD87_STAAU  0.27925\n",
       "Q9FD86_STAAU  0.08545\n",
       "KIME_YEAST    0.35120\n",
       "ERG8_YEAST    0.48190"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Objective value {opt_model.gbt.outputs[0].value}\")\n",
    "\n",
    "next_x = [opt_model.gbt.inputs[idx].value for idx in range(len(opt_model.gbt.inputs))]\n",
    "next_x = pd.DataFrame(\n",
    "    data=next_x, index=df_A.columns.drop(\"Limonene\"), columns=[\"Value\"]\n",
    ")\n",
    "next_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
