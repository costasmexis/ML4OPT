{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mexis\\anaconda3\\envs\\main\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING: DEPRECATED: Declaring class 'OmltBlockData' derived from\n",
      "'_BlockData'. The class '_BlockData' has been renamed to 'BlockData'.\n",
      "(deprecated in 6.7.2) (called from\n",
      "c:\\Users\\mexis\\anaconda3\\envs\\main\\lib\\site-packages\\omlt\\block.py:33)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import pyomo.environ as pyo\n",
    "from pyomo.opt import SolverFactory\n",
    "from src.ewenpyomo import ewen_model\n",
    "from src.neural_network import create_nn, data_scaling\n",
    "from src.omlt_model import create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OMLT__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 7)\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "df = pd.read_csv('../data/datasetcost.csv')\n",
    "\n",
    "inputs = list(df.columns)\n",
    "inputs.remove('total_cost')\n",
    "outputs = ['total_cost']\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "# Data scaling\n",
    "x, y, x_offset, x_factor, \\\n",
    "    y_offset, y_factor, scaled_lb, scaled_ub = data_scaling(df, inputs, outputs)\n",
    "    \n",
    "# Create and train a ANN\n",
    "# net = create_nn(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mexis\\anaconda3\\envs\\main\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from omlt import OffsetScaling, OmltBlock\n",
    "from omlt.io.keras import load_keras_sequential\n",
    "from omlt.neuralnet import (\n",
    "    FullSpaceNNFormulation,\n",
    "    FullSpaceSmoothNNFormulation,\n",
    "    NetworkDefinition,\n",
    "    ReducedSpaceSmoothNNFormulation,\n",
    "    ReluBigMFormulation,\n",
    "    ReluComplementarityFormulation,\n",
    "    ReluPartitionFormulation,\n",
    ")\n",
    "\n",
    "omlt_model = pyo.ConcreteModel()\n",
    "omlt_model.cost = OmltBlock()\n",
    "nn_cost = keras.models.load_model('cost_nn.keras', compile=False)\n",
    "\n",
    "scaler = OffsetScaling(\n",
    "    offset_inputs={i: x_offset[inputs[i]] for i in range(len(inputs))},\n",
    "    factor_inputs={i: x_factor[inputs[i]] for i in range(len(inputs))},\n",
    "    offset_outputs={i: y_offset[outputs[i]] for i in range(len(outputs))},\n",
    "    factor_outputs={i: y_factor[outputs[i]] for i in range(len(outputs))},\n",
    ")\n",
    "\n",
    "scaled_input_bounds = {i: (scaled_lb[i], scaled_ub[i]) for i in range(len(inputs))}\n",
    "\n",
    "net = load_keras_sequential(\n",
    "    nn_cost, scaling_object=scaler, scaled_input_bounds=scaled_input_bounds\n",
    ")\n",
    "omlt_model.cost.build_formulation(FullSpaceSmoothNNFormulation(net))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ewen basic model\n",
    "ewen_pyomo_model = ewen_model()\n",
    "\n",
    "# Create merged model\n",
    "model = pyo.ConcreteModel()\n",
    "model.model1 = ewen_pyomo_model\n",
    "model.model2 = omlt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = outputs.index('total_cost')\n",
    "\n",
    "# Create objective function\n",
    "model.obj = pyo.Objective(expr=model.model1.EFTotal + 3 * model.model2.cost.outputs[cost], sense=pyo.minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FiR_1 = inputs.index('Fir1')\n",
    "FiR_2 = inputs.index('Fir2')\n",
    "FiR_3 = inputs.index('Fir3')\n",
    "CiR_1 = inputs.index('Cir1')\n",
    "CiR_2 = inputs.index('Cir2')\n",
    "CiR_3 = inputs.index('Cir3')\n",
    "\n",
    "model.constraint1 = pyo.Constraint(expr=model.model1.FiR[1] == model.model2.cost.inputs[FiR_1])\n",
    "model.constraint2 = pyo.Constraint(expr=model.model1.FiR[2] == model.model2.cost.inputs[FiR_2])\n",
    "model.constraint3 = pyo.Constraint(expr=model.model1.FiR[3] == model.model2.cost.inputs[FiR_3])\n",
    "\n",
    "model.constraint4 = pyo.Constraint(expr=model.model1.CiR[1] == model.model2.cost.inputs[CiR_1])\n",
    "model.constraint5 = pyo.Constraint(expr=model.model1.CiR[2] == model.model2.cost.inputs[CiR_2])\n",
    "model.constraint6 = pyo.Constraint(expr=model.model1.CiR[3] == model.model2.cost.inputs[CiR_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = pyo.SolverFactory('ipopt')\n",
    "results = solver.solve(model, tee=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFTotal value: 247.8242168879322\n",
      "cost value: 40.63118910910668\n",
      "ERTotal value: 204.92952376802086\n",
      "interc value: 28.0\n",
      "\n",
      "FiR_1 = 42.64562206819553\n",
      "FiR_2 = 26.678511566852073\n",
      "FiR_3 = 135.60539013297327\n",
      "\n",
      "CiR_1 = 6396.843252884609\n",
      "CiR_2 = 4001.7764910475307\n",
      "CiR_3 = 29999.27876057934\n",
      "\n",
      "CoR_1 = 852.9124415208918\n",
      "CoR_2 = 266.78511574743635\n",
      "CoR_3 = 1356.0539014086482\n"
     ]
    }
   ],
   "source": [
    "print(f'EFTotal value: {model.obj()}')\n",
    "print(f'cost value: {model.model2.cost.outputs[cost].value}')\n",
    "print(f'ERTotal value: {model.model1.ERTotal()}')\n",
    "print(f'interc value: {model.model1.interc()}')\n",
    "print()\n",
    "print(f'FiR_1 = {model.model1.FiR[1].value}')\n",
    "print(f'FiR_2 = {model.model1.FiR[2].value}')\n",
    "print(f'FiR_3 = {model.model1.FiR[3].value}')\n",
    "print()\n",
    "print(f'CiR_1 = {model.model1.CiR[1].value}')\n",
    "print(f'CiR_2 = {model.model1.CiR[2].value}')\n",
    "print(f'CiR_3 = {model.model1.CiR[3].value}')\n",
    "print()\n",
    "print(f'CoR_1 = {model.model1.CoR[1].value}')\n",
    "print(f'CoR_2 = {model.model1.CoR[2].value}')\n",
    "print(f'CoR_3 = {model.model1.CoR[3].value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
